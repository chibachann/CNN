{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを格納するリスト\n",
    "X = []\n",
    "Z = []\n",
    "\n",
    "# 画像のサイズ\n",
    "IMG_SIZE = 150\n",
    "\n",
    "# 各花のディレクトリのパス\n",
    "FLOWER_DAISY_DIR = '../input/flowers/daisy'\n",
    "FLOWER_DANDI_DIR = '../input/flowers/dandelion'\n",
    "FLOWER_ROSE_DIR = '../input/flowers/rose'\n",
    "FLOWER_SUNFLOWER_DIR = '../input/flowers/sunflower'\n",
    "FLOWER_TULIP_DIR = '../input/flowers/tulip'\n",
    "\n",
    "# フラグを初期化\n",
    "added_flowers = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの格納とコメントを追加した関数\n",
    "def make_train_data(flower_type, DIR):\n",
    "    if flower_type not in added_flowers:\n",
    "        added_flowers.add(flower_type)\n",
    "        # 各花のデータを格納するためのループ\n",
    "        for img in tqdm(os.listdir(DIR)):\n",
    "            # ラベルを花の名前に設定\n",
    "            label = str(flower_type)\n",
    "            # 画像ファイルのパスを生成\n",
    "            path = os.path.join(DIR, img)\n",
    "            # 画像をカラーで読み込み\n",
    "            img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "            # 画像サイズをリサイズ\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            # データをリストに追加\n",
    "            X.append(np.array(img))\n",
    "            Z.append(str(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764/764 [00:01<00:00, 562.85it/s]\n",
      "100%|██████████| 1052/1052 [00:01<00:00, 552.03it/s]\n",
      "100%|██████████| 784/784 [00:01<00:00, 555.45it/s]\n",
      "100%|██████████| 733/733 [00:01<00:00, 467.01it/s]\n",
      "100%|██████████| 984/984 [00:01<00:00, 532.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# 各花に対してデータを作成\n",
    "make_train_data('Daisy', FLOWER_DAISY_DIR)\n",
    "make_train_data('Dandelion', FLOWER_DANDI_DIR)\n",
    "make_train_data('Rose', FLOWER_ROSE_DIR)\n",
    "make_train_data('Sunflower', FLOWER_SUNFLOWER_DIR)\n",
    "make_train_data('Tulip', FLOWER_TULIP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データの前処理\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Z)\n",
    "Y = torch.tensor(Y, dtype=torch.long)\n",
    "X = np.array(X)\n",
    "X = X / 255.0  # ピクセル値を正規化\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "X = X.permute(0, 3, 1, 2)  # PyTorchはチャネルを先に要求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを訓練セットと検証セットに分割\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 最初の畳み込み層：32フィルタ、5x5カーネル、ReLU活性化関数、入力チャネルは3（RGB）\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding='same')\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 二番目の畳み込み層：64フィルタ、3x3カーネル、ReLU活性化関数\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 三番目の畳み込み層：96フィルタ、3x3カーネル、ReLU活性化関数\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, padding='same')\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 四番目の畳み込み層：96フィルタ、3x3カーネル、ReLU活性化関数\n",
    "        self.conv4 = nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, padding='same')\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten層\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 全結合層\n",
    "        self.fc1 = nn.Linear(96 * 9 * 9, 512)  # 96フィルタ、9x9サイズ（入力サイズに依存）\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        # 出力層：5クラスに分類するための層\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = self.pool4(self.relu4(self.conv4(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu5(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. モデルの構築\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 訓練と検証\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 訓練フェーズ\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}, Training...'):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 検証フェーズ\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs}, Validation...'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 損失と精度の計算\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        train_accuracies.append(train_correct / len(train_loader.dataset))\n",
    "        val_accuracies.append(val_correct / len(val_loader.dataset))\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}, Train Acc: {train_accuracies[-1]}, Val Acc: {val_accuracies[-1]}')\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Training...:  86%|████████▌ | 93/108 [00:36<00:05,  2.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tairy\\Documents\\Machine Learning\\CNN\\notebooks\\2 copy.ipynb セル 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m criterion_fold \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# 各フォールドでのモデルの訓練と評価\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies \u001b[39m=\u001b[39m train_and_evaluate_model(model_fold, train_loader_fold, val_loader_fold, criterion_fold, optimizer_fold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# 各フォールドの結果をプロット\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\tairy\\Documents\\Machine Learning\\CNN\\notebooks\\2 copy.ipynb セル 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Training...\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\tairy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\tairy\\Documents\\Machine Learning\\CNN\\notebooks\\2 copy.ipynb セル 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20copy.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)))\n",
      "File \u001b[1;32mc:\\Users\\tairy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tairy\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mmax_pool2d(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    167\u001b[0m                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, ceil_mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mceil_mode,\n\u001b[0;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_indices)\n",
      "File \u001b[1;32mc:\\Users\\tairy\\anaconda3\\Lib\\site-packages\\torch\\_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tairy\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmax_pool2d(\u001b[39minput\u001b[39m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 交差検証の設定\n",
    "kf = KFold(n_splits=5)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    Y_train_fold, Y_val_fold = Y[train_idx], Y[val_idx]\n",
    "\n",
    "    train_dataset_fold = TensorDataset(X_train_fold, Y_train_fold)\n",
    "    val_dataset_fold = TensorDataset(X_val_fold, Y_val_fold)\n",
    "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=32, shuffle=True)\n",
    "    val_loader_fold = DataLoader(val_dataset_fold, batch_size=32, shuffle=False)\n",
    "\n",
    "    model_fold = SimpleCNN()\n",
    "    optimizer_fold = torch.optim.Adam(model_fold.parameters(), lr=0.001)\n",
    "    criterion_fold = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 各フォールドでのモデルの訓練と評価\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_and_evaluate_model(model_fold, train_loader_fold, val_loader_fold, criterion_fold, optimizer_fold)\n",
    "\n",
    "    # 各フォールドの結果をプロット\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(f'Losses at Fold {fold+1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy at Fold {fold+1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
