{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPUが利用可能かどうかを確認し、利用可能ならGPUを使用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを格納するリスト\n",
    "X = []\n",
    "Z = []\n",
    "\n",
    "# 画像のサイズ\n",
    "IMG_SIZE = 150\n",
    "\n",
    "# 各花のディレクトリのパス\n",
    "FLOWER_DAISY_DIR = '../input/flowers/daisy'\n",
    "FLOWER_DANDI_DIR = '../input/flowers/dandelion'\n",
    "FLOWER_ROSE_DIR = '../input/flowers/rose'\n",
    "FLOWER_SUNFLOWER_DIR = '../input/flowers/sunflower'\n",
    "FLOWER_TULIP_DIR = '../input/flowers/tulip'\n",
    "\n",
    "# フラグを初期化\n",
    "added_flowers = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの格納とコメントを追加した関数\n",
    "def make_train_data(flower_type, DIR):\n",
    "    if flower_type not in added_flowers:\n",
    "        added_flowers.add(flower_type)\n",
    "        # 各花のデータを格納するためのループ\n",
    "        for img in tqdm(os.listdir(DIR)):\n",
    "            # ラベルを花の名前に設定\n",
    "            label = str(flower_type)\n",
    "            # 画像ファイルのパスを生成\n",
    "            path = os.path.join(DIR, img)\n",
    "            # 画像をカラーで読み込み\n",
    "            img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "            # 画像サイズをリサイズ\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "            # データをリストに追加\n",
    "            X.append(np.array(img))\n",
    "            Z.append(str(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764/764 [00:00<00:00, 836.30it/s]\n",
      "100%|██████████| 1052/1052 [00:01<00:00, 801.78it/s]\n",
      "100%|██████████| 784/784 [00:00<00:00, 833.16it/s]\n",
      "100%|██████████| 733/733 [00:01<00:00, 685.69it/s]\n",
      "100%|██████████| 984/984 [00:01<00:00, 779.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# 各花に対してデータを作成\n",
    "make_train_data('Daisy', FLOWER_DAISY_DIR)\n",
    "make_train_data('Dandelion', FLOWER_DANDI_DIR)\n",
    "make_train_data('Rose', FLOWER_ROSE_DIR)\n",
    "make_train_data('Sunflower', FLOWER_SUNFLOWER_DIR)\n",
    "make_train_data('Tulip', FLOWER_TULIP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データの前処理\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Z)\n",
    "Y = torch.tensor(Y, dtype=torch.long)\n",
    "X = np.array(X)\n",
    "X = X / 255.0  # ピクセル値を正規化\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "X = X.permute(0, 3, 1, 2)  # PyTorchはチャネルを先に要求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを訓練セットと検証セットに分割\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 最初の畳み込み層：32フィルタ、5x5カーネル、ReLU活性化関数、入力チャネルは3（RGB）\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding='same')\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 二番目の畳み込み層：64フィルタ、3x3カーネル、ReLU活性化関数\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 三番目の畳み込み層：96フィルタ、3x3カーネル、ReLU活性化関数\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, padding='same')\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 四番目の畳み込み層：96フィルタ、3x3カーネル、ReLU活性化関数\n",
    "        self.conv4 = nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, padding='same')\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten層\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 全結合層\n",
    "        self.fc1 = nn.Linear(96 * 9 * 9, 512)  # 96フィルタ、9x9サイズ（入力サイズに依存）\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        # 出力層：5クラスに分類するための層\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = self.pool4(self.relu4(self.conv4(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu5(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルをデバイスに移動\n",
    "model = SimpleCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 訓練と検証\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 訓練フェーズ\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}, Training...'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 検証フェーズ\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs}, Validation...'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 損失と精度の計算\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        train_accuracies.append(train_correct / len(train_loader.dataset))\n",
    "        val_accuracies.append(val_correct / len(val_loader.dataset))\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}, Train Acc: {train_accuracies[-1]}, Val Acc: {val_accuracies[-1]}')\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Training...: 100%|██████████| 108/108 [00:02<00:00, 46.99it/s]\n",
      "Epoch 1/25, Validation...: 100%|██████████| 27/27 [00:00<00:00, 122.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 1.102254111457754, Val Loss: 7.13832414039859, Train Acc: 0.4891398783666377, Val Acc: 0.10532407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Training...: 100%|██████████| 108/108 [00:01<00:00, 56.12it/s]\n",
      "Epoch 2/25, Validation...: 100%|██████████| 27/27 [00:00<00:00, 125.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Train Loss: 0.8795229643583298, Val Loss: 8.986828870243496, Train Acc: 0.6353895163625832, Val Acc: 0.08564814814814815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Training...: 100%|██████████| 108/108 [00:01<00:00, 56.11it/s]\n",
      "Epoch 3/25, Validation...: 100%|██████████| 27/27 [00:00<00:00, 125.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Train Loss: 0.7750070619362371, Val Loss: 8.548739431080994, Train Acc: 0.6710107153200116, Val Acc: 0.09953703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Training...:  97%|█████████▋| 105/108 [00:01<00:00, 56.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tairy\\Documents\\Machine Learning\\CNN\\notebooks\\2 gpu.ipynb セル 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m criterion_fold \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# 各フォールドでのモデルの訓練と評価\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies \u001b[39m=\u001b[39m train_and_evaluate_model(model_fold, train_loader_fold, val_loader_fold, criterion_fold, optimizer_fold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# 各フォールドの結果を保存\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m all_train_losses\u001b[39m.\u001b[39mappend(train_losses)\n",
      "\u001b[1;32mc:\\Users\\tairy\\Documents\\Machine Learning\\CNN\\notebooks\\2 gpu.ipynb セル 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_loss, train_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Training...\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "all_train_accuracies = []\n",
    "all_val_accuracies = []\n",
    "\n",
    "# 交差検証の設定\n",
    "kf = KFold(n_splits=5)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f'Fold {fold+1}')\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    Y_train_fold, Y_val_fold = Y[train_idx], Y[val_idx]\n",
    "\n",
    "    train_dataset_fold = TensorDataset(X_train_fold, Y_train_fold)\n",
    "    val_dataset_fold = TensorDataset(X_val_fold, Y_val_fold)\n",
    "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=32, shuffle=True)\n",
    "    val_loader_fold = DataLoader(val_dataset_fold, batch_size=32, shuffle=False)\n",
    "\n",
    "    model_fold = SimpleCNN().to(device)\n",
    "    optimizer_fold = torch.optim.Adam(model_fold.parameters(), lr=0.001)\n",
    "    criterion_fold = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 各フォールドでのモデルの訓練と評価\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_and_evaluate_model(model_fold, train_loader_fold, val_loader_fold, criterion_fold, optimizer_fold)\n",
    "\n",
    "    # 各フォールドの結果を保存\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_val_losses.append(val_losses)\n",
    "    all_train_accuracies.append(train_accuracies)\n",
    "    all_val_accuracies.append(val_accuracies)\n",
    "\n",
    "    # 各フォールドの結果をプロット\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(f'Losses at Fold {fold+1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy at Fold {fold+1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均損失と精度の計算\n",
    "avg_train_loss = np.mean([np.mean(losses) for losses in all_train_losses])\n",
    "avg_val_loss = np.mean([np.mean(losses) for losses in all_val_losses])\n",
    "avg_train_acc = np.mean([np.mean(accs) for accs in all_train_accuracies])\n",
    "avg_val_acc = np.mean([np.mean(accs) for accs in all_val_accuracies])\n",
    "\n",
    "print(f'Average Train Loss: {avg_train_loss}, Average Validation Loss: {avg_val_loss}')\n",
    "print(f'Average Train Accuracy: {avg_train_acc}, Average Validation Accuracy: {avg_val_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tairy\\Documents\\Machine Learning\\CNN\\notebooks\\2 gpu.ipynb セル 14\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(all_train_losses)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(all_train_losses[i], label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain Fold \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tairy/Documents/Machine%20Learning/CNN/notebooks/2%20gpu.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(all_val_losses[i], label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVal Fold \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_train_losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 各フォールドの結果をまとめてプロット\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "for i in range(len(all_train_losses)):\n",
    "    plt.plot(all_train_losses[i], label=f'Train Fold {i+1}')\n",
    "    plt.plot(all_val_losses[i], label=f'Val Fold {i+1}', linestyle='--')\n",
    "plt.title('Train and Validation Losses Across Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "for i in range(len(all_train_accuracies)):\n",
    "    plt.plot(all_train_accuracies[i], label=f'Train Fold {i+1}')\n",
    "    plt.plot(all_val_accuracies[i], label=f'Val Fold {i+1}', linestyle='--')\n",
    "plt.title('Train and Validation Accuracies Across Folds')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
